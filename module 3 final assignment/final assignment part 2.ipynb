{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 771948_A23_T3A - Group Work Assignment #\n",
    "# Task 2 - Multi-label image-based digit classification problem #\n",
    "## Assignment by Chris Mintz 202369825 and Antonia Agunbiade 202375309 ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Additional notes from class chat ###\n",
    "#### 1. Labels from dataset will be folder names\n",
    "#### 2. Beware of the multi image model classifying into triplets instead of single digits. The output shape should be 1000 instead of 10\n",
    "#### 3. DO NOT recombine the split data. It has to be used as is as per TA Khadjia\n",
    "#### 4. From Khadjia: The provided splits into training, validation and testing were designed to simulate real-world scenarios. Teams must develop a baseline model using these splits and gthen improve upon this baseline through various techniques such as preprocessing and model architecture enhancements.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6 - Load and preprocess the dataset for multi-label image-based digit classification task\n",
    "\n",
    "## <b>References</b>\n",
    "\n",
    "Johns, Ray. (2024). PyTorch vs TensorFlow for your Python Deep Learning Project. Available at: https://realpython.com/pytorch-vs-tensorflow/. [Accessed Aug 5, 2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this assignment we have chosen to use the TensorFlow over PyTorch as TensorFlow 2.0 has eager execution and the Keras APIs have more prefabricated components for us to use.\n",
    "import tensorflow as tf\n",
    "# TO DO: we might be able to remove this global import\n",
    "from tensorflow import keras\n",
    "# Needed for image pre-processing\n",
    "from PIL import Image\n",
    "# there is a lint problem access problem with the latest release of TensorFlow/Keras so we have to go direct to the root call\n",
    "from keras._tf_keras.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras._tf_keras.keras.models import Sequential\n",
    "from keras._tf_keras.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, Input\n",
    "# we want these for some visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# for image processing\n",
    "import os\n",
    "\n",
    "# Change directory location as needed. This should be the root of the unzipped dataset and the initial folder visible shuold be \"triple_mnist\" \n",
    "# -------------------------------------------\n",
    "dataset_root_dir = 'z:'\n",
    "# -------------------------------------------\n",
    "\n",
    "# Define our data split directory locations\n",
    "training_dir = dataset_root_dir + '\\\\triple_mnist\\\\train'\n",
    "validate_dir = dataset_root_dir + '\\\\triple_mnist\\\\val'\n",
    "test_dir = dataset_root_dir + '\\\\triple_mnist\\\\test'\n",
    "\n",
    "# Define our image parameters\n",
    "image_height = 84\n",
    "image_width = 84\n",
    "batch_size = 32\n",
    "# these are grayscale images, so we will only have 1 channel and this will be enforced in the data loading process\n",
    "channels = 1\n",
    "# output classes will be 0 to 9 which = 10\n",
    "num_classes = 10\n",
    "#TODO: Optimize\n",
    "epochs = 10\n",
    "\n",
    "# Data augmentation and preprocessing parameters to initialize the ImageDataGenerator\n",
    "# Transformations we are NOT using include: zoom_range, horizontal_flip, vertical_flip, fill_mode, channel_shift_range, brightness_range, zca_epsilon, zca_whitening\n",
    "# Note that we had the opportunity to use the \"preprocessing_function\" parameter to crop the images as needed but we chose to persist the cropped images to disk to prevent\n",
    "# this function from being called with each epoch. This is because the cropping function is computationally expensive and we only need to do it once.\n",
    "idg = ImageDataGenerator(\n",
    "    rescale=1./255,          # Normalize pixel values to [0, 1]\n",
    "    shear_range=0.2,         # Apply shear transformations\n",
    "    rotation_range=40,       # Randomly rotate images by up to 40 degrees\n",
    "    width_shift_range=0.2,   # Randomly shift images horizontally by up to 20% of the width\n",
    "    height_shift_range=0.2,   # Randomly shift images vertically by up to 20% of the height\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing to get the triplet digit data into single values\n",
    "### The data came to us as a series of triplet hand written numbers meaning that in the 84 x 84 image there are three images. Upon inspection there is a clean divide between all digits despite them having random y placement in the frame. Our best approach is to take the file name, divide the image into three and then save out the single hand written digit to a new folder. To manage this in memory could be costly so we will check if the images exist on your disk, write them if necessary, but read them from pre-processesd state if they have already been cleaned in your local dataset. We will watch for images that get cropped but even that might be only a couple of pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the function will crop a triplet digit image into three separate images and return them as a list of three images.\n",
    "# this function does not manage disk persistence, it is only for in-memory processing\n",
    "def crop_image(image):\n",
    "    image_return = []\n",
    "    x_cropsize = 28\n",
    "    y_cropsize = 84\n",
    "    x_croplength = x_cropsize/2\n",
    "    y_croplength = y_cropsize/2\n",
    "    # define the centers of the three cropped images and the crop size will go to the edge coords from there\n",
    "    x_centers = [14, 42, 70]\n",
    "    y_centers = [42, 42, 42]\n",
    "    # create the three cropped images\n",
    "    for i in range(3):\n",
    "        image_return[i] = image.crop((x_centers[i]-x_croplength, y_centers[i]-y_croplength, x_centers[i]+x_croplength, y_centers[i]+y_croplength))\n",
    "        \n",
    "    return image_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function lets us look at our images in the datasets\n",
    "# let's peek into the dataset by loading the first batch of num_to_show images\n",
    "def datset_peek(idg_show: ImageDataGenerator, num_to_show: int):\n",
    "\n",
    "    # Display the first num_to_show digits in the training training_generator\n",
    "    fig, ax = plt.subplots(1, num_to_show, figsize=(20, 20))\n",
    "    for i in range(num_to_show):\n",
    "        ax[i].imshow(np.squeeze(idg_show[0][0][i]), cmap='gray')\n",
    "        ax[i].set_title(f'Label: {idg_show[0][1][i]}')\n",
    "        ax[i].axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING: Has hardcoded values for the image to load\n",
    "#TODO: This code can be trashed as all it does is draw a bounding box. Maybe make it a def function?\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Load an image\n",
    "image_path = training_dir + \"/175/11_175.png\"\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_jpeg(image, channels=1)\n",
    "image = tf.image.resize(image, [84, 84])\n",
    "\n",
    "# Define bounding boxes (normalized coordinates: [y_min, x_min, y_max, x_max])\n",
    "bounding_boxes = tf.constant([[0.1, 0.1, 0.5, 0.5], [0.6, 0.6, 0.9, 0.9], [0.2, 0.3, 0.8, 0.7]])\n",
    "\n",
    "# Convert bounding boxes to pixel coordinates\n",
    "image_height, image_width, _ = image.shape\n",
    "bounding_boxes_pixel = bounding_boxes * [image_height, image_width, image_height, image_width]\n",
    "\n",
    "# Visualize the bounding boxes\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image.numpy().astype(\"uint8\"))\n",
    "\n",
    "for box in bounding_boxes_pixel:\n",
    "    y_min, x_min, y_max, x_max = box\n",
    "    rect = patches.Rectangle((x_min, y_min), x_max - x_min, y_max - y_min, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "folder index 0: 0_000.png loaded successfully from z:\\triple_mnist\\train\\000\\0_000.png.\n",
      "folder index 0: 10_000.png loaded successfully from z:\\triple_mnist\\train\\000\\10_000.png.\n",
      "folder index 0: 11_000.png loaded successfully from z:\\triple_mnist\\train\\000\\11_000.png.\n",
      "folder index 0: 12_000.png loaded successfully from z:\\triple_mnist\\train\\000\\12_000.png.\n",
      "folder index 0: 13_000.png loaded successfully from z:\\triple_mnist\\train\\000\\13_000.png.\n",
      "folder index 0: 14_000.png loaded successfully from z:\\triple_mnist\\train\\000\\14_000.png.\n",
      "folder index 0: 15_000.png loaded successfully from z:\\triple_mnist\\train\\000\\15_000.png.\n",
      "folder index 0: 16_000.png loaded successfully from z:\\triple_mnist\\train\\000\\16_000.png.\n",
      "folder index 0: 17_000.png loaded successfully from z:\\triple_mnist\\train\\000\\17_000.png.\n",
      "folder index 0: 18_000.png loaded successfully from z:\\triple_mnist\\train\\000\\18_000.png.\n",
      "folder index 0: 19_000.png loaded successfully from z:\\triple_mnist\\train\\000\\19_000.png.\n",
      "folder index 0: 1_000.png loaded successfully from z:\\triple_mnist\\train\\000\\1_000.png.\n",
      "folder index 0: 20_000.png loaded successfully from z:\\triple_mnist\\train\\000\\20_000.png.\n",
      "folder index 0: 21_000.png loaded successfully from z:\\triple_mnist\\train\\000\\21_000.png.\n",
      "folder index 0: 22_000.png loaded successfully from z:\\triple_mnist\\train\\000\\22_000.png.\n",
      "folder index 0: 23_000.png loaded successfully from z:\\triple_mnist\\train\\000\\23_000.png.\n",
      "folder index 0: 24_000.png loaded successfully from z:\\triple_mnist\\train\\000\\24_000.png.\n",
      "folder index 0: 25_000.png loaded successfully from z:\\triple_mnist\\train\\000\\25_000.png.\n",
      "folder index 0: 26_000.png loaded successfully from z:\\triple_mnist\\train\\000\\26_000.png.\n",
      "folder index 0: 27_000.png loaded successfully from z:\\triple_mnist\\train\\000\\27_000.png.\n",
      "folder index 0: 28_000.png loaded successfully from z:\\triple_mnist\\train\\000\\28_000.png.\n",
      "folder index 0: 29_000.png loaded successfully from z:\\triple_mnist\\train\\000\\29_000.png.\n",
      "folder index 0: 2_000.png loaded successfully from z:\\triple_mnist\\train\\000\\2_000.png.\n",
      "folder index 0: 30_000.png loaded successfully from z:\\triple_mnist\\train\\000\\30_000.png.\n",
      "folder index 0: 31_000.png loaded successfully from z:\\triple_mnist\\train\\000\\31_000.png.\n",
      "folder index 0: 32_000.png loaded successfully from z:\\triple_mnist\\train\\000\\32_000.png.\n",
      "folder index 0: 33_000.png loaded successfully from z:\\triple_mnist\\train\\000\\33_000.png.\n",
      "folder index 0: 34_000.png loaded successfully from z:\\triple_mnist\\train\\000\\34_000.png.\n",
      "folder index 0: 35_000.png loaded successfully from z:\\triple_mnist\\train\\000\\35_000.png.\n",
      "folder index 0: 36_000.png loaded successfully from z:\\triple_mnist\\train\\000\\36_000.png.\n",
      "folder index 0: 37_000.png loaded successfully from z:\\triple_mnist\\train\\000\\37_000.png.\n",
      "folder index 0: 38_000.png loaded successfully from z:\\triple_mnist\\train\\000\\38_000.png.\n",
      "folder index 0: 39_000.png loaded successfully from z:\\triple_mnist\\train\\000\\39_000.png.\n",
      "folder index 0: 3_000.png loaded successfully from z:\\triple_mnist\\train\\000\\3_000.png.\n",
      "folder index 0: 40_000.png loaded successfully from z:\\triple_mnist\\train\\000\\40_000.png.\n",
      "folder index 0: 41_000.png loaded successfully from z:\\triple_mnist\\train\\000\\41_000.png.\n",
      "folder index 0: 42_000.png loaded successfully from z:\\triple_mnist\\train\\000\\42_000.png.\n",
      "folder index 0: 43_000.png loaded successfully from z:\\triple_mnist\\train\\000\\43_000.png.\n",
      "folder index 0: 44_000.png loaded successfully from z:\\triple_mnist\\train\\000\\44_000.png.\n",
      "folder index 0: 45_000.png loaded successfully from z:\\triple_mnist\\train\\000\\45_000.png.\n",
      "folder index 0: 46_000.png loaded successfully from z:\\triple_mnist\\train\\000\\46_000.png.\n",
      "folder index 0: 47_000.png loaded successfully from z:\\triple_mnist\\train\\000\\47_000.png.\n",
      "folder index 0: 48_000.png loaded successfully from z:\\triple_mnist\\train\\000\\48_000.png.\n",
      "folder index 0: 49_000.png loaded successfully from z:\\triple_mnist\\train\\000\\49_000.png.\n",
      "folder index 0: 4_000.png loaded successfully from z:\\triple_mnist\\train\\000\\4_000.png.\n",
      "folder index 0: 50_000.png loaded successfully from z:\\triple_mnist\\train\\000\\50_000.png.\n",
      "folder index 0: 51_000.png loaded successfully from z:\\triple_mnist\\train\\000\\51_000.png.\n",
      "folder index 0: 52_000.png loaded successfully from z:\\triple_mnist\\train\\000\\52_000.png.\n",
      "folder index 0: 53_000.png loaded successfully from z:\\triple_mnist\\train\\000\\53_000.png.\n",
      "folder index 0: 54_000.png loaded successfully from z:\\triple_mnist\\train\\000\\54_000.png.\n",
      "folder index 0: 55_000.png loaded successfully from z:\\triple_mnist\\train\\000\\55_000.png.\n",
      "folder index 0: 56_000.png loaded successfully from z:\\triple_mnist\\train\\000\\56_000.png.\n",
      "folder index 0: 57_000.png loaded successfully from z:\\triple_mnist\\train\\000\\57_000.png.\n",
      "folder index 0: 58_000.png loaded successfully from z:\\triple_mnist\\train\\000\\58_000.png.\n",
      "folder index 0: 59_000.png loaded successfully from z:\\triple_mnist\\train\\000\\59_000.png.\n",
      "folder index 0: 5_000.png loaded successfully from z:\\triple_mnist\\train\\000\\5_000.png.\n",
      "folder index 0: 60_000.png loaded successfully from z:\\triple_mnist\\train\\000\\60_000.png.\n",
      "folder index 0: 61_000.png loaded successfully from z:\\triple_mnist\\train\\000\\61_000.png.\n",
      "folder index 0: 62_000.png loaded successfully from z:\\triple_mnist\\train\\000\\62_000.png.\n",
      "folder index 0: 63_000.png loaded successfully from z:\\triple_mnist\\train\\000\\63_000.png.\n",
      "folder index 0: 64_000.png loaded successfully from z:\\triple_mnist\\train\\000\\64_000.png.\n",
      "folder index 0: 65_000.png loaded successfully from z:\\triple_mnist\\train\\000\\65_000.png.\n",
      "folder index 0: 66_000.png loaded successfully from z:\\triple_mnist\\train\\000\\66_000.png.\n",
      "folder index 0: 67_000.png loaded successfully from z:\\triple_mnist\\train\\000\\67_000.png.\n",
      "folder index 0: 68_000.png loaded successfully from z:\\triple_mnist\\train\\000\\68_000.png.\n",
      "folder index 0: 69_000.png loaded successfully from z:\\triple_mnist\\train\\000\\69_000.png.\n",
      "folder index 0: 6_000.png loaded successfully from z:\\triple_mnist\\train\\000\\6_000.png.\n",
      "folder index 0: 70_000.png loaded successfully from z:\\triple_mnist\\train\\000\\70_000.png.\n",
      "folder index 0: 71_000.png loaded successfully from z:\\triple_mnist\\train\\000\\71_000.png.\n",
      "folder index 0: 72_000.png loaded successfully from z:\\triple_mnist\\train\\000\\72_000.png.\n",
      "folder index 0: 73_000.png loaded successfully from z:\\triple_mnist\\train\\000\\73_000.png.\n",
      "folder index 0: 74_000.png loaded successfully from z:\\triple_mnist\\train\\000\\74_000.png.\n",
      "folder index 0: 75_000.png loaded successfully from z:\\triple_mnist\\train\\000\\75_000.png.\n",
      "folder index 0: 76_000.png loaded successfully from z:\\triple_mnist\\train\\000\\76_000.png.\n",
      "folder index 0: 77_000.png loaded successfully from z:\\triple_mnist\\train\\000\\77_000.png.\n",
      "folder index 0: 78_000.png loaded successfully from z:\\triple_mnist\\train\\000\\78_000.png.\n",
      "folder index 0: 79_000.png loaded successfully from z:\\triple_mnist\\train\\000\\79_000.png.\n",
      "folder index 0: 7_000.png loaded successfully from z:\\triple_mnist\\train\\000\\7_000.png.\n",
      "folder index 0: 80_000.png loaded successfully from z:\\triple_mnist\\train\\000\\80_000.png.\n",
      "folder index 0: 81_000.png loaded successfully from z:\\triple_mnist\\train\\000\\81_000.png.\n",
      "folder index 0: 82_000.png loaded successfully from z:\\triple_mnist\\train\\000\\82_000.png.\n",
      "folder index 0: 83_000.png loaded successfully from z:\\triple_mnist\\train\\000\\83_000.png.\n",
      "folder index 0: 84_000.png loaded successfully from z:\\triple_mnist\\train\\000\\84_000.png.\n",
      "folder index 0: 85_000.png loaded successfully from z:\\triple_mnist\\train\\000\\85_000.png.\n",
      "folder index 0: 86_000.png loaded successfully from z:\\triple_mnist\\train\\000\\86_000.png.\n",
      "folder index 0: 87_000.png loaded successfully from z:\\triple_mnist\\train\\000\\87_000.png.\n",
      "folder index 0: 88_000.png loaded successfully from z:\\triple_mnist\\train\\000\\88_000.png.\n",
      "folder index 0: 89_000.png loaded successfully from z:\\triple_mnist\\train\\000\\89_000.png.\n",
      "folder index 0: 8_000.png loaded successfully from z:\\triple_mnist\\train\\000\\8_000.png.\n",
      "folder index 0: 90_000.png loaded successfully from z:\\triple_mnist\\train\\000\\90_000.png.\n",
      "folder index 0: 91_000.png loaded successfully from z:\\triple_mnist\\train\\000\\91_000.png.\n",
      "folder index 0: 92_000.png loaded successfully from z:\\triple_mnist\\train\\000\\92_000.png.\n",
      "folder index 0: 93_000.png loaded successfully from z:\\triple_mnist\\train\\000\\93_000.png.\n",
      "folder index 0: 94_000.png loaded successfully from z:\\triple_mnist\\train\\000\\94_000.png.\n",
      "folder index 0: 95_000.png loaded successfully from z:\\triple_mnist\\train\\000\\95_000.png.\n",
      "folder index 0: 96_000.png loaded successfully from z:\\triple_mnist\\train\\000\\96_000.png.\n",
      "folder index 0: 97_000.png loaded successfully from z:\\triple_mnist\\train\\000\\97_000.png.\n",
      "folder index 0: 98_000.png loaded successfully from z:\\triple_mnist\\train\\000\\98_000.png.\n",
      "folder index 0: 99_000.png loaded successfully from z:\\triple_mnist\\train\\000\\99_000.png.\n",
      "folder index 0: 9_000.png loaded successfully from z:\\triple_mnist\\train\\000\\9_000.png.\n"
     ]
    }
   ],
   "source": [
    "# WARNING - this code might commit 300,000 files to your file drive and will take a long time to run\n",
    "# Check and see if the triplet images have been cropped and saved to your drive\n",
    "training_preprocessed_path = dataset_root_dir + '\\\\triple_mnist\\\\train_preprocessed'\n",
    "validate_preprocessed_path = dataset_root_dir + '\\\\triple_mnist\\\\val_preprocessed'\n",
    "test_preprocessed_path = dataset_root_dir + '\\\\triple_mnist\\\\test_preprocessed'\n",
    "if os.path.exists(training_preprocessed_path):\n",
    "    print('Training preprocessed images exist')\n",
    "else:\n",
    "    all_folders = os.listdir(training_dir)\n",
    "    # Enumerate and load the directories\n",
    "    cropped_images = []\n",
    "    for index, image_folder in enumerate(all_folders):\n",
    "        # now go through each directory and get the images\n",
    "        curr_files = os.listdir(os.path.join(training_dir, image_folder))\n",
    "        for image_file in curr_files:\n",
    "            file_path = os.path.join(training_dir, image_folder, image_file)\n",
    "            try:\n",
    "                image = Image.open(file_path)\n",
    "                cropped_images.append(image)\n",
    "                print(f'folder index {index}: {image_file} loaded successfully from {file_path}.')\n",
    "            except PermissionError as e:\n",
    "                print(f'Permission denied, please launch VS Code as admin: {e}')\n",
    "            except Exception as e:\n",
    "                print(f'An error occurred: {e}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the images from a locally mapped source (see README.md for details on setting up local drive mapping)\n",
    "# We've used the idg to load only the training images and preprocess them with the above parameters\n",
    "# Images are brought in as grayscale (single channel) as they are black and white images\n",
    "training_generator = idg.flow_from_directory(\n",
    "    training_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "# Our test and validation data should not be augmented so their init is simpler and does not use our predefined idg parameters\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "# Note use of validation data but no augmentation\n",
    "validation_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "    validate_dir,\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check and see if all the images are the same shape before feeding them into the model\n",
    "print(f'training generator shape {training_generator.image_shape}')\n",
    "print(f'validation generator shape {validation_generator.image_shape}')\n",
    "print(f'test generator shape {test_generator.image_shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7 - Build a convultional neural network (CNN) model for the multi-label image-based digit classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Don't forget to use Dropout layers to prevent overfitting\n",
    "# Model setup\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(image_height, image_width, channels)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "# Adjust the final layer to match the target shape\n",
    "model.add(Dense(640, activation='softmax'))\n",
    "\n",
    "# Show the model summary and ensure the final layer count matches our desired output of 10 as defined in the final Dense layer.\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to fit the model\n",
    "model.fit(training_generator, epochs=1, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parked model for now\n",
    "model.fit(\n",
    "        training_generator,\n",
    "        steps_per_epoch=training_generator.samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // batch_size,\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8 - Fine-tune the CNN model using appropriate techniques like hyperparameter tuning, cross-validation, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 9 - Visualize the dataset and the CNN model's results where applicable with feature maps, learning curves, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 10 - Report the final performance of the CNN model using appropriate performance metrics like accuracy, F1-score, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 11 -Decide on the best model for classification and CNN architecture for digital recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
